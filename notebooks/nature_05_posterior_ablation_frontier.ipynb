{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Experiment: Nature Evidence 05 - Posterior Ablation and Compute-Quality Frontier\n",
        "\n",
        "Objective:\n",
        "- Quantify the compute-vs-quality tradeoff of posterior inference settings.\n",
        "- Select a production recommendation using reproducible Pareto analysis rather than intuition.\n",
        "- Evaluate measurement protocol design choices that improve reliability under fixed compute.\n",
        "\n",
        "Success criteria:\n",
        "- A ranked set of inference configurations with explicit runtime and quality metrics.\n",
        "- A recommended \"balanced\" config justified by measured tradeoffs.\n",
        "- Protocol-level evidence showing that better observation design improves inference quality.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Setup: imports and reproducibility\n",
        "from __future__ import annotations\n",
        "\n",
        "import json\n",
        "import os\n",
        "import time\n",
        "from pathlib import Path\n",
        "\n",
        "import equinox as eqx\n",
        "import jax\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from ecsfm.fm.eval_classical import _resolve_model_geometry\n",
        "from ecsfm.fm.model import VectorFieldNet\n",
        "from ecsfm.fm.posterior import CEMPosteriorConfig, PosteriorInferenceConfig, infer_parameter_posterior\n",
        "from ecsfm.fm.train import (\n",
        "    MODEL_META_FILENAME,\n",
        "    NORMALIZERS_FILENAME,\n",
        "    load_model_metadata,\n",
        "    load_saved_normalizers,\n",
        ")\n",
        "\n",
        "np.random.seed(2026)\n",
        "\n",
        "ARTIFACT_DIR = Path('/tmp/ecsfm/notebook_nature_05')\n",
        "ARTIFACT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "print(f'Artifacts: {ARTIFACT_DIR}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plan\n",
        "\n",
        "- Load one trained model and one held-out chunk.\n",
        "- Build a fixed evaluation set of partial/noisy observations.\n",
        "- Run configuration ablations and compute a Pareto frontier.\n",
        "- Select a recommendation and test multiple observation-mask protocols.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# User-facing configuration and data/model loading\n",
        "def _first_existing(candidates: list[Path]) -> Path | None:\n",
        "    for candidate in candidates:\n",
        "        if candidate.exists():\n",
        "            return candidate\n",
        "    return None\n",
        "\n",
        "\n",
        "def _discover_latest(pattern: str, roots: list[Path]) -> Path | None:\n",
        "    found: list[Path] = []\n",
        "    for root in roots:\n",
        "        if root.exists():\n",
        "            found.extend(root.rglob(pattern))\n",
        "    if not found:\n",
        "        return None\n",
        "    return max(found, key=lambda p: p.stat().st_mtime)\n",
        "\n",
        "\n",
        "checkpoint_override = os.getenv('ECSFM_CHECKPOINT')\n",
        "dataset_override = os.getenv('ECSFM_DATASET_CHUNK')\n",
        "\n",
        "checkpoint_candidates = [\n",
        "    Path('/tmp/ecsfm/fullscale_balanced_modal/surrogate_model.eqx'),\n",
        "    Path('/vol/artifacts/fullscale_balanced_modal/surrogate_model.eqx'),\n",
        "    Path('/tmp/ecsfm/surrogate_model.eqx'),\n",
        "]\n",
        "dataset_candidates = [\n",
        "    Path('/tmp/ecsfm/dataset_balanced_742k/chunk_0.npz'),\n",
        "    Path('/vol/datasets/dataset_balanced_742k/chunk_0.npz'),\n",
        "    Path('/tmp/ecsfm/dataset_massive/chunk_0.npz'),\n",
        "]\n",
        "\n",
        "if checkpoint_override:\n",
        "    CHECKPOINT = Path(checkpoint_override)\n",
        "else:\n",
        "    CHECKPOINT = _first_existing(checkpoint_candidates)\n",
        "    if CHECKPOINT is None:\n",
        "        CHECKPOINT = _discover_latest('surrogate_model.eqx', [Path('/tmp/ecsfm'), Path('/vol/artifacts')])\n",
        "\n",
        "if dataset_override:\n",
        "    DATASET_CHUNK = Path(dataset_override)\n",
        "else:\n",
        "    DATASET_CHUNK = _first_existing(dataset_candidates)\n",
        "    if DATASET_CHUNK is None:\n",
        "        DATASET_CHUNK = _discover_latest('chunk_0.npz', [Path('/tmp/ecsfm'), Path('/vol/datasets')])\n",
        "    if DATASET_CHUNK is None:\n",
        "        DATASET_CHUNK = _discover_latest('chunk_*.npz', [Path('/tmp/ecsfm'), Path('/vol/datasets')])\n",
        "\n",
        "if CHECKPOINT is None or not CHECKPOINT.exists():\n",
        "    raise FileNotFoundError('Checkpoint not found. Set ECSFM_CHECKPOINT.')\n",
        "if DATASET_CHUNK is None or not DATASET_CHUNK.exists():\n",
        "    raise FileNotFoundError('Dataset chunk not found. Set ECSFM_DATASET_CHUNK.')\n",
        "\n",
        "N_CASES = 5\n",
        "EVAL_NOISE_STD = 0.08\n",
        "\n",
        "CONFIGS = [\n",
        "    {'name': 'fast', 'n_particles': 32, 'n_iters': 3, 'elite_frac': 0.25, 'n_mc': 1, 'n_steps': 40},\n",
        "    {'name': 'balanced', 'n_particles': 64, 'n_iters': 4, 'elite_frac': 0.25, 'n_mc': 2, 'n_steps': 60},\n",
        "    {'name': 'robust', 'n_particles': 96, 'n_iters': 6, 'elite_frac': 0.25, 'n_mc': 3, 'n_steps': 100},\n",
        "]\n",
        "\n",
        "normalizers = load_saved_normalizers(CHECKPOINT.parent / NORMALIZERS_FILENAME)\n",
        "meta = load_model_metadata(CHECKPOINT.parent / MODEL_META_FILENAME)\n",
        "geometry = _resolve_model_geometry(normalizers, meta)\n",
        "\n",
        "key = jax.random.PRNGKey(np.uint32(2026))\n",
        "_, model_key = jax.random.split(key)\n",
        "model = VectorFieldNet(\n",
        "    state_dim=int(geometry['state_dim']),\n",
        "    hidden_size=int(meta.get('hidden_size', 128)),\n",
        "    depth=int(meta.get('depth', 3)),\n",
        "    cond_dim=int(meta.get('cond_dim', 32)),\n",
        "    phys_dim=int(geometry['phys_dim']),\n",
        "    signal_channels=int(geometry['signal_channels']),\n",
        "    key=model_key,\n",
        ")\n",
        "model = eqx.tree_deserialise_leaves(CHECKPOINT, model)\n",
        "\n",
        "with np.load(DATASET_CHUNK) as chunk:\n",
        "    currents = np.asarray(chunk['i'], dtype=np.float32)\n",
        "    signals = np.asarray(chunk['e'], dtype=np.float32)\n",
        "    params_base = np.asarray(chunk['p'], dtype=np.float32)\n",
        "    task_ids = np.asarray(chunk['task_id'], dtype=np.int32)\n",
        "    stage_ids = np.asarray(chunk['stage_id'], dtype=np.int32)\n",
        "\n",
        "rng = np.random.default_rng(2027)\n",
        "case_indices = np.asarray(rng.choice(currents.shape[0], size=min(N_CASES, currents.shape[0]), replace=False), dtype=np.int32)\n",
        "\n",
        "phys_dim_base = int(geometry['phys_dim_base'])\n",
        "phys_dim_core = int(geometry['phys_dim_core'])\n",
        "n_tasks = int(geometry['n_tasks'])\n",
        "n_stages = int(geometry['n_stages'])\n",
        "\n",
        "\n",
        "def compose_core_params(base_row: np.ndarray, task_idx: int, stage_idx: int) -> np.ndarray:\n",
        "    out = np.zeros((phys_dim_core,), dtype=np.float32)\n",
        "    out[:phys_dim_base] = base_row[:phys_dim_base]\n",
        "    cursor = phys_dim_base\n",
        "    if n_tasks > 0:\n",
        "        onehot = np.zeros((n_tasks,), dtype=np.float32)\n",
        "        onehot[int(np.clip(task_idx, 0, n_tasks - 1))] = 1.0\n",
        "        out[cursor : cursor + n_tasks] = onehot\n",
        "        cursor += n_tasks\n",
        "    if n_stages > 0:\n",
        "        onehot = np.zeros((n_stages,), dtype=np.float32)\n",
        "        onehot[int(np.clip(stage_idx, 0, n_stages - 1))] = 1.0\n",
        "        out[cursor : cursor + n_stages] = onehot\n",
        "    return out\n",
        "\n",
        "\n",
        "p_core_true = np.stack(\n",
        "    [compose_core_params(params_base[i], int(task_ids[i]), int(stage_ids[i])) for i in case_indices],\n",
        "    axis=0,\n",
        ")\n",
        "\n",
        "_, _, _, _, p_mean, p_std = normalizers\n",
        "p_mean = np.asarray(p_mean, dtype=np.float32)\n",
        "p_std = np.asarray(p_std, dtype=np.float32)\n",
        "\n",
        "print('checkpoint:', CHECKPOINT)\n",
        "print('dataset chunk:', DATASET_CHUNK)\n",
        "print('cases:', case_indices.tolist())\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Measurement protocols: random sparse vs transition-focused vs dense\n",
        "def mask_random(length: int, keep_prob: float, rng: np.random.Generator, min_points: int = 24) -> np.ndarray:\n",
        "    mask = rng.random(length) < keep_prob\n",
        "    if int(mask.sum()) < min_points:\n",
        "        idx = rng.choice(length, size=min(min_points, length), replace=False)\n",
        "        mask[idx] = True\n",
        "    return mask.astype(np.float32)\n",
        "\n",
        "\n",
        "def mask_transition_focused(signal: np.ndarray, keep_fraction: float, min_points: int = 24) -> np.ndarray:\n",
        "    signal = np.asarray(signal, dtype=float)\n",
        "    length = signal.shape[0]\n",
        "    n_keep = max(min_points, int(round(keep_fraction * length)))\n",
        "    grad = np.abs(np.gradient(signal))\n",
        "    idx = np.argsort(grad)[-n_keep:]\n",
        "    mask = np.zeros((length,), dtype=bool)\n",
        "    mask[idx] = True\n",
        "    anchors = np.linspace(0, length - 1, num=min_points, dtype=int)\n",
        "    mask[anchors] = True\n",
        "    return mask.astype(np.float32)\n",
        "\n",
        "\n",
        "protocol_measurements: dict[str, list[dict[str, np.ndarray]]] = {\n",
        "    'dense': [],\n",
        "    'random_sparse': [],\n",
        "    'transition_focus': [],\n",
        "}\n",
        "\n",
        "for local_idx, row_idx in enumerate(case_indices):\n",
        "    rng_case = np.random.default_rng(3000 + int(row_idx))\n",
        "    signal = np.asarray(signals[row_idx], dtype=np.float32)\n",
        "    truth = np.asarray(currents[row_idx], dtype=np.float32)\n",
        "    noisy = truth + rng_case.normal(0.0, EVAL_NOISE_STD, size=truth.shape[0]).astype(np.float32)\n",
        "\n",
        "    protocol_measurements['dense'].append(\n",
        "        {'signal': signal, 'obs_current': noisy, 'mask': np.ones_like(noisy, dtype=np.float32)}\n",
        "    )\n",
        "    protocol_measurements['random_sparse'].append(\n",
        "        {\n",
        "            'signal': signal,\n",
        "            'obs_current': noisy,\n",
        "            'mask': mask_random(noisy.shape[0], keep_prob=0.35, rng=rng_case),\n",
        "        }\n",
        "    )\n",
        "    protocol_measurements['transition_focus'].append(\n",
        "        {\n",
        "            'signal': signal,\n",
        "            'obs_current': noisy,\n",
        "            'mask': mask_transition_focused(signal, keep_fraction=0.35),\n",
        "        }\n",
        "    )\n",
        "\n",
        "print('Prepared measurement protocols for', len(case_indices), 'cases.')\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Config ablation on the random_sparse protocol\n",
        "known_mask = np.zeros((phys_dim_core,), dtype=bool)\n",
        "known_mask[phys_dim_base:] = True\n",
        "\n",
        "ablation_records: list[dict[str, float | str | int]] = []\n",
        "\n",
        "for cfg in CONFIGS:\n",
        "    for local_idx, row_idx in enumerate(case_indices):\n",
        "        meas = protocol_measurements['random_sparse'][local_idx]\n",
        "        posterior_cfg = PosteriorInferenceConfig(\n",
        "            cem=CEMPosteriorConfig(\n",
        "                n_particles=int(cfg['n_particles']),\n",
        "                n_iterations=int(cfg['n_iters']),\n",
        "                elite_fraction=float(cfg['elite_frac']),\n",
        "            ),\n",
        "            n_mc_per_particle=int(cfg['n_mc']),\n",
        "            n_integration_steps=int(cfg['n_steps']),\n",
        "            obs_noise_std=float(EVAL_NOISE_STD),\n",
        "        )\n",
        "\n",
        "        t0 = time.perf_counter()\n",
        "        post = infer_parameter_posterior(\n",
        "            model=model,\n",
        "            normalizers=normalizers,\n",
        "            geometry=geometry,\n",
        "            observed_current=meas['obs_current'],\n",
        "            applied_signal=meas['signal'],\n",
        "            known_p_core=p_core_true[local_idx],\n",
        "            known_p_mask=known_mask,\n",
        "            obs_mask=meas['mask'],\n",
        "            config=posterior_cfg,\n",
        "            seed=9000 + local_idx + int(cfg['n_particles']),\n",
        "        )\n",
        "        elapsed = float(time.perf_counter() - t0)\n",
        "\n",
        "        true_norm = ((p_core_true[local_idx] - p_mean) / p_std)[:phys_dim_base]\n",
        "        post_mean_norm = np.asarray(post['posterior_mean_norm'], dtype=np.float32)[:phys_dim_base]\n",
        "        param_nrmse = float(np.sqrt(np.mean((post_mean_norm - true_norm) ** 2)))\n",
        "        rel = dict(post['reliability'])\n",
        "\n",
        "        ablation_records.append(\n",
        "            {\n",
        "                'config': str(cfg['name']),\n",
        "                'case_index': int(row_idx),\n",
        "                'elapsed_s': elapsed,\n",
        "                'param_nrmse': param_nrmse,\n",
        "                'reliability_score': float(rel['reliability_score']),\n",
        "                'pred_nrmse': float(rel['nrmse']),\n",
        "                'pred_nll': float(rel['nll']),\n",
        "                'pred_calibration_error': float(rel['calibration_error']),\n",
        "                'n_particles': int(cfg['n_particles']),\n",
        "                'n_iters': int(cfg['n_iters']),\n",
        "                'n_mc': int(cfg['n_mc']),\n",
        "                'n_steps': int(cfg['n_steps']),\n",
        "            }\n",
        "        )\n",
        "\n",
        "\n",
        "def summarize_config(name: str) -> dict[str, float | str]:\n",
        "    rows = [r for r in ablation_records if r['config'] == name]\n",
        "    arr = lambda key: np.asarray([float(r[key]) for r in rows], dtype=float)\n",
        "    return {\n",
        "        'config': name,\n",
        "        'elapsed_s_mean': float(np.mean(arr('elapsed_s'))),\n",
        "        'param_nrmse_mean': float(np.mean(arr('param_nrmse'))),\n",
        "        'reliability_score_mean': float(np.mean(arr('reliability_score'))),\n",
        "        'pred_calibration_error_mean': float(np.mean(arr('pred_calibration_error'))),\n",
        "        'pred_nll_mean': float(np.mean(arr('pred_nll'))),\n",
        "    }\n",
        "\n",
        "\n",
        "config_summary = [summarize_config(cfg['name']) for cfg in CONFIGS]\n",
        "\n",
        "\n",
        "def is_dominated(a: dict[str, float | str], b: dict[str, float | str]) -> bool:\n",
        "    qa = float(a['reliability_score_mean'])\n",
        "    ta = float(a['elapsed_s_mean'])\n",
        "    qb = float(b['reliability_score_mean'])\n",
        "    tb = float(b['elapsed_s_mean'])\n",
        "    return (qb >= qa and tb <= ta) and (qb > qa or tb < ta)\n",
        "\n",
        "\n",
        "pareto = []\n",
        "for row in config_summary:\n",
        "    dominated = any(is_dominated(row, other) for other in config_summary if other is not row)\n",
        "    if not dominated:\n",
        "        pareto.append(row)\n",
        "\n",
        "baseline_time = min(float(r['elapsed_s_mean']) for r in config_summary)\n",
        "utilities = []\n",
        "for row in config_summary:\n",
        "    score = float(row['reliability_score_mean'])\n",
        "    time_penalty = float(row['elapsed_s_mean']) / max(baseline_time, 1e-9)\n",
        "    utility = score - 6.0 * time_penalty\n",
        "    utilities.append((utility, row['config']))\n",
        "recommended_config_name = max(utilities)[1]\n",
        "\n",
        "print('--- config summary ---')\n",
        "for row in sorted(config_summary, key=lambda x: -float(x['reliability_score_mean'])):\n",
        "    print(\n",
        "        f\"{row['config']:9s} \"\n",
        "        f\"R={row['reliability_score_mean']:.2f} \"\n",
        "        f\"param_nrmse={row['param_nrmse_mean']:.3f} \"\n",
        "        f\"time={row['elapsed_s_mean']:.2f}s \"\n",
        "        f\"cal={row['pred_calibration_error_mean']:.3f}\"\n",
        "    )\n",
        "print('pareto:', [row['config'] for row in pareto])\n",
        "print('recommended:', recommended_config_name)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Visualize compute-quality frontier\n",
        "fig, ax = plt.subplots(figsize=(7.5, 5.5))\n",
        "\n",
        "for row in config_summary:\n",
        "    x = float(row['elapsed_s_mean'])\n",
        "    y = float(row['reliability_score_mean'])\n",
        "    ax.scatter(x, y, s=90)\n",
        "    ax.text(x * 1.02, y + 0.2, str(row['config']), fontsize=9)\n",
        "\n",
        "if pareto:\n",
        "    pareto_sorted = sorted(pareto, key=lambda r: float(r['elapsed_s_mean']))\n",
        "    ax.plot(\n",
        "        [float(r['elapsed_s_mean']) for r in pareto_sorted],\n",
        "        [float(r['reliability_score_mean']) for r in pareto_sorted],\n",
        "        'k--',\n",
        "        alpha=0.7,\n",
        "        label='Pareto frontier',\n",
        "    )\n",
        "\n",
        "ax.set_xlabel('Mean runtime per case (s)')\n",
        "ax.set_ylabel('Mean reliability score')\n",
        "ax.set_title('Posterior Inference Compute-Quality Frontier')\n",
        "ax.grid(alpha=0.3)\n",
        "ax.legend()\n",
        "fig.tight_layout()\n",
        "fig.savefig(ARTIFACT_DIR / 'posterior_ablation_frontier.png', dpi=180)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Protocol design study using the recommended config\n",
        "cfg_map = {cfg['name']: cfg for cfg in CONFIGS}\n",
        "chosen_cfg = cfg_map[recommended_config_name]\n",
        "\n",
        "protocol_records: list[dict[str, float | str | int]] = []\n",
        "for protocol_name, measurements in protocol_measurements.items():\n",
        "    for local_idx, row_idx in enumerate(case_indices):\n",
        "        meas = measurements[local_idx]\n",
        "        posterior_cfg = PosteriorInferenceConfig(\n",
        "            cem=CEMPosteriorConfig(\n",
        "                n_particles=int(chosen_cfg['n_particles']),\n",
        "                n_iterations=int(chosen_cfg['n_iters']),\n",
        "                elite_fraction=float(chosen_cfg['elite_frac']),\n",
        "            ),\n",
        "            n_mc_per_particle=int(chosen_cfg['n_mc']),\n",
        "            n_integration_steps=int(chosen_cfg['n_steps']),\n",
        "            obs_noise_std=float(EVAL_NOISE_STD),\n",
        "        )\n",
        "\n",
        "        post = infer_parameter_posterior(\n",
        "            model=model,\n",
        "            normalizers=normalizers,\n",
        "            geometry=geometry,\n",
        "            observed_current=meas['obs_current'],\n",
        "            applied_signal=meas['signal'],\n",
        "            known_p_core=p_core_true[local_idx],\n",
        "            known_p_mask=known_mask,\n",
        "            obs_mask=meas['mask'],\n",
        "            config=posterior_cfg,\n",
        "            seed=12000 + local_idx,\n",
        "        )\n",
        "\n",
        "        true_norm = ((p_core_true[local_idx] - p_mean) / p_std)[:phys_dim_base]\n",
        "        post_mean_norm = np.asarray(post['posterior_mean_norm'], dtype=np.float32)[:phys_dim_base]\n",
        "        param_nrmse = float(np.sqrt(np.mean((post_mean_norm - true_norm) ** 2)))\n",
        "        rel = dict(post['reliability'])\n",
        "\n",
        "        protocol_records.append(\n",
        "            {\n",
        "                'protocol': protocol_name,\n",
        "                'case_index': int(row_idx),\n",
        "                'obs_fraction': float(np.mean(np.asarray(meas['mask']) >= 0.5)),\n",
        "                'param_nrmse': param_nrmse,\n",
        "                'reliability_score': float(rel['reliability_score']),\n",
        "                'pred_calibration_error': float(rel['calibration_error']),\n",
        "            }\n",
        "        )\n",
        "\n",
        "\n",
        "def summarize_protocol(name: str) -> dict[str, float | str]:\n",
        "    rows = [r for r in protocol_records if r['protocol'] == name]\n",
        "    arr = lambda key: np.asarray([float(r[key]) for r in rows], dtype=float)\n",
        "    return {\n",
        "        'protocol': name,\n",
        "        'obs_fraction_mean': float(np.mean(arr('obs_fraction'))),\n",
        "        'param_nrmse_mean': float(np.mean(arr('param_nrmse'))),\n",
        "        'reliability_score_mean': float(np.mean(arr('reliability_score'))),\n",
        "        'pred_calibration_error_mean': float(np.mean(arr('pred_calibration_error'))),\n",
        "    }\n",
        "\n",
        "\n",
        "protocol_summary = [summarize_protocol(name) for name in protocol_measurements]\n",
        "protocol_summary = sorted(protocol_summary, key=lambda r: -float(r['reliability_score_mean']))\n",
        "\n",
        "print('--- protocol summary (using', recommended_config_name, ') ---')\n",
        "for row in protocol_summary:\n",
        "    print(\n",
        "        f\"{row['protocol']:16s} \"\n",
        "        f\"R={row['reliability_score_mean']:.2f} \"\n",
        "        f\"param_nrmse={row['param_nrmse_mean']:.3f} \"\n",
        "        f\"obs_frac={row['obs_fraction_mean']:.3f} \"\n",
        "        f\"cal={row['pred_calibration_error_mean']:.3f}\"\n",
        "    )\n",
        "\n",
        "payload = {\n",
        "    'config': {\n",
        "        'checkpoint': str(CHECKPOINT),\n",
        "        'dataset_chunk': str(DATASET_CHUNK),\n",
        "        'case_indices': case_indices.tolist(),\n",
        "        'eval_noise_std': EVAL_NOISE_STD,\n",
        "        'configs': CONFIGS,\n",
        "        'recommended_config': recommended_config_name,\n",
        "    },\n",
        "    'ablation_summary': config_summary,\n",
        "    'pareto_configs': [row['config'] for row in pareto],\n",
        "    'ablation_records': ablation_records,\n",
        "    'protocol_summary': protocol_summary,\n",
        "    'protocol_records': protocol_records,\n",
        "}\n",
        "with open(ARTIFACT_DIR / 'posterior_ablation_protocols.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(payload, f, indent=2)\n",
        "\n",
        "protocols = [row['protocol'] for row in protocol_summary]\n",
        "rel = np.asarray([row['reliability_score_mean'] for row in protocol_summary], dtype=float)\n",
        "prm = np.asarray([row['param_nrmse_mean'] for row in protocol_summary], dtype=float)\n",
        "cal = np.asarray([row['pred_calibration_error_mean'] for row in protocol_summary], dtype=float)\n",
        "\n",
        "x = np.arange(len(protocols))\n",
        "width = 0.28\n",
        "fig, ax = plt.subplots(figsize=(10, 5))\n",
        "ax.bar(x - width, rel, width, label='reliability score')\n",
        "ax.bar(x, prm, width, label='param nrmse')\n",
        "ax.bar(x + width, cal, width, label='calibration error')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(protocols)\n",
        "ax.set_title('Protocol Design Impact (recommended inference config)')\n",
        "ax.grid(axis='y', alpha=0.3)\n",
        "ax.legend(fontsize=8)\n",
        "fig.tight_layout()\n",
        "fig.savefig(ARTIFACT_DIR / 'posterior_protocol_design_comparison.png', dpi=180)\n",
        "plt.show()\n",
        "\n",
        "protocol_summary\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Results and reviewer-facing interpretation\n",
        "\n",
        "- This notebook makes compute-quality tradeoffs explicit, with a Pareto frontier and a reproducible recommendation rule.\n",
        "- The recommended configuration is not assumed; it is selected from measured reliability, calibration, and runtime.\n",
        "- Protocol design (where/when observations are taken) can materially improve inverse inference quality under a fixed compute budget.\n",
        "\n",
        "## Improvement actions from this notebook\n",
        "\n",
        "- Use the recommended config as default for balanced production runs.\n",
        "- For resource-constrained runs, retain fast mode but require stricter reliability gating.\n",
        "- Prefer transition-focused measurement schedules when dense sampling is impractical.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
